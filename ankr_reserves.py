import asyncio
import aiohttp
from web3 import Web3
from typing import Dict, List, Optional, Tuple
import json

class AnkrReservesProvider:
    def __init__(self, api_key: str, w3: Web3, logger):
        self.api_key = api_key
        self.w3 = w3
        self.logger = logger
        self.ankr_url = f"https://rpc.ankr.com/polygon/{api_key}"
        self.session = None  # –í–ê–ñ–ù–û: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session –∫–∞–∫ None
    
    async def ensure_session(self):
        """–°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–µ—Å—Å–∏—é"""
        if not self.session or self.session.closed:
            self.session = aiohttp.ClientSession()
            self.logger.debug("–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è HTTP —Å–µ—Å—Å–∏—è –¥–ª—è ANKR")
    
    async def get_reserves_batch(self, pairs: List[str]) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –¢–û–õ–¨–ö–û —Ä–µ–∑–µ—Ä–≤—ã –¥–ª—è —Å–ø–∏—Å–∫–∞ –ø–∞—Ä —á–µ—Ä–µ–∑ Ankr (–±–µ–∑ token0/token1)"""
        
        if not pairs:
            return {}
            
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Å–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞ –û–î–ò–ù –†–ê–ó
        await self.ensure_session()
        
        reserves_map = {}
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞—Ç—á –¢–û–õ–¨–ö–û –¥–ª—è getReserves (1 –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–∞—Ä—É –≤–º–µ—Å—Ç–æ 3)
        batch_payload = []
        
        for i, pair_address in enumerate(pairs):
            batch_payload.append({
                "jsonrpc": "2.0",
                "method": "eth_call",
                "params": [{
                    "to": pair_address,
                    "data": "0x0902f1ac"  # getReserves()
                }, "latest"],
                "id": i + 1
            })
            
        try:
            self.logger.debug(f"–û—Ç–ø—Ä–∞–≤–ª—è—é ANKR –±–∞—Ç—á –∏–∑ {len(batch_payload)} –∑–∞–ø—Ä–æ—Å–æ–≤...")
            # –û–î–ò–ù –∑–∞–ø—Ä–æ—Å —Å–æ –í–°–ï–ú–ò –≤—ã–∑–æ–≤–∞–º–∏ —Å—Ä–∞–∑—É
            async with self.session.post(self.ankr_url, json=batch_payload, timeout=30) as response:
                results = await response.json()
                
                # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                if isinstance(results, list):
                    for i, pair_address in enumerate(pairs):
                        if i < len(results) and "result" in results[i]:
                            data = results[i]["result"]
                            if data and data != "0x":
                                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑–µ—Ä–≤—ã
                                reserve0 = int(data[2:66], 16) if len(data) >= 66 else 0
                                reserve1 = int(data[66:130], 16) if len(data) >= 130 else 0
                                
                                reserves_map[pair_address] = {
                                    'reserve0': reserve0,
                                    'reserve1': reserve1,
                                    'token0': None,  # –ù–µ –∑–∞–≥—Ä—É–∂–∞–µ–º
                                    'token1': None   # –ù–µ –∑–∞–≥—Ä—É–∂–∞–µ–º
                                }
                else:
                    # ANKR –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É –≤ –≤–∏–¥–µ dict (rate limit –∏–ª–∏ –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞)
                    if isinstance(results, dict):
                        if "error" in results:
                            self.logger.debug(f"ANKR –æ—à–∏–±–∫–∞: {results.get('error', {}).get('message', 'Unknown error')}")
                        else:
                            self.logger.debug(f"ANKR –≤–µ—Ä–Ω—É–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π dict: {results}")
                    else:
                        self.logger.debug(f"ANKR –≤–µ—Ä–Ω—É–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {type(results)}")
                            
        except asyncio.TimeoutError:
            self.logger.error(f"‚è±Ô∏è ANKR timeout –¥–ª—è –±–∞—Ç—á–∞ –∏–∑ {len(pairs)} –ø–∞—Ä")
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ ANKR –±–∞—Ç—á-–∑–∞–ø—Ä–æ—Å–∞: {e}")
        
        return reserves_map
    
    async def get_reserves_many(self, pairs: List[str]) -> Dict[str, Tuple]:
        """–ú–∞—Å—Å–æ–≤–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–æ–≤ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏ —á–µ—Ä–µ–∑ ANKR"""
        if not pairs:
            return {}
        
        import time
        start_time = time.time()
        unique_pairs = list(set(pairs))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        
        # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ë–ï–ó–û–ü–ê–°–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´
        BATCH_SIZE = 30  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (10 –ø–∞—Ä = 30 –∑–∞–ø—Ä–æ—Å–æ–≤) - –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        CONCURRENCY = 1   # –ë–ï–ó –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏ - —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
        MIN_BATCH_SIZE = 2  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏ –¥–µ–ª–µ–Ω–∏–∏ –ø–æ–ø–æ–ª–∞–º
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–ª–∞–Ω
        n_batches = (len(unique_pairs) + BATCH_SIZE - 1) // BATCH_SIZE
        self.logger.info(f"üîÑ fetch_reserves: {len(unique_pairs)} pairs ‚Üí {n_batches} –±–∞—Ç—á–µ–π ({CONCURRENCY} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)")
        
        # –ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã –Ω–µ –Ω–∞–≥—Ä—É–∂–∞—Ç—å ANKR —Å—Ä–∞–∑—É
        await asyncio.sleep(1.0)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏
        batches = []
        for i in range(0, len(unique_pairs), BATCH_SIZE):
            batch = unique_pairs[i:i + BATCH_SIZE]
            batches.append(batch)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        all_reserves = {}
        for i in range(0, len(batches), CONCURRENCY):
            concurrent_batches = batches[i:i + CONCURRENCY]
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –±–∞—Ç—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            tasks = []
            for batch in concurrent_batches:
                task = self._process_batch_with_retry(batch)
                tasks.append(task)
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –±–∞—Ç—á–µ–π –≤ –≥—Ä—É–ø–ø–µ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for result in results:
                if isinstance(result, dict):
                    self.logger.debug(f"–ë–∞—Ç—á –≤–µ—Ä–Ω—É–ª {len(result)} –ø–∞—Ä")
                    all_reserves.update(result)
                elif isinstance(result, Exception):
                    self.logger.warning(f"Batch failed: {result}")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–∞—Ä
            processed = len(all_reserves)  # –†–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–∞—Ä
            self.logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed}/{len(unique_pairs)} –ø–∞—Ä")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ –±–∞—Ç—á–µ–π —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å rate limit
            if processed < len(unique_pairs):
                await asyncio.sleep(1.0)  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ 1 —Å–µ–∫—É–Ω–¥–∞
        
        elapsed = time.time() - start_time
        self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ä–µ–∑–µ—Ä–≤–æ–≤: {len(all_reserves)}/{len(unique_pairs)} –∑–∞ {elapsed:.2f}s")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –∫–æ—Ä—Ç–µ–∂–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        result = {}
        for pair, data in all_reserves.items():
            if isinstance(data, dict):
                result[pair] = (
                    data.get('reserve0', 0),
                    data.get('reserve1', 0),
                    data.get('token0'),
                    data.get('token1')
                )
        return result
    
    async def _process_batch_with_retry(self, batch: List[str], retry_count: int = 0) -> Dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Å retry –∏ –¥–µ–ª–µ–Ω–∏–µ–º –ø–æ–ø–æ–ª–∞–º –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        MAX_RETRIES = 3
        MIN_BATCH_SIZE = 2  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏ –¥–µ–ª–µ–Ω–∏–∏ –ø–æ–ø–æ–ª–∞–º
        
        try:
            # –ü—Ä–æ–±—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á —Ü–µ–ª–∏–∫–æ–º —á–µ—Ä–µ–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
            result = await self.get_reserves_batch(batch)
            if result:
                return result
            
            # –ï—Å–ª–∏ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –º–æ–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å
            if len(batch) > MIN_BATCH_SIZE and retry_count < MAX_RETRIES:
                self.logger.debug(f"Batch failed, splitting {len(batch)} ‚Üí {len(batch)//2}")
                
                # –î–µ–ª–∏–º –ø–æ–ø–æ–ª–∞–º
                mid = len(batch) // 2
                left_batch = batch[:mid]
                right_batch = batch[mid:]
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–ª–æ–≤–∏–Ω–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
                left_task = self._process_batch_with_retry(left_batch, retry_count + 1)
                right_task = self._process_batch_with_retry(right_batch, retry_count + 1)
                
                left_result, right_result = await asyncio.gather(left_task, right_task)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                combined = {}
                if left_result:
                    combined.update(left_result)
                if right_result:
                    combined.update(right_result)
                return combined
            
            return {}
            
        except asyncio.TimeoutError:
            if retry_count < MAX_RETRIES:
                # Backoff: 2s, 4s, 8s - –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–∏ rate limit
                backoff = min(2.0 * (2 ** retry_count), 10.0)
                self.logger.debug(f"Timeout, retry {retry_count + 1}/{MAX_RETRIES} after {backoff}s")
                await asyncio.sleep(backoff)
                return await self._process_batch_with_retry(batch, retry_count + 1)
            else:
                self.logger.error(f"Batch timeout after {MAX_RETRIES} retries")
                return {}
        except Exception as e:
            error_str = str(e).lower()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ rate limit
            if 'rate limit' in error_str or 'too many' in error_str or '429' in error_str:
                if retry_count < MAX_RETRIES:
                    backoff = min(2.0 * (2 ** retry_count), 10.0)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É: 2s, 4s, 8s
                    self.logger.debug(f"Rate limit, retry {retry_count + 1}/{MAX_RETRIES} after {backoff}s")
                    await asyncio.sleep(backoff)
                    return await self._process_batch_with_retry(batch, retry_count + 1)
            
            self.logger.error(f"Batch error: {e}")
            return {}
    
    async def get_decimals_many(self, tokens: List[str]) -> Dict[str, int]:
        """–ú–∞—Å—Å–æ–≤–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ decimals —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ ANKR"""
        if not tokens:
            return {}
        
        import time
        import json
        from pathlib import Path
        
        start_time = time.time()
        unique_tokens = list(set(tokens))
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—ç—à
        cache_dir = Path("cache")
        cache_file = cache_dir / "decimals.json"
        decimals_cache = {}
        
        if cache_file.exists():
            try:
                with open(cache_file, 'r') as f:
                    decimals_cache = json.load(f)
                self.logger.debug(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω –∫—ç—à decimals: {len(decimals_cache)} —Ç–æ–∫–µ–Ω–æ–≤")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫—ç—à decimals: {e}")
        else:
            cache_dir.mkdir(exist_ok=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        result = {}
        tokens_to_fetch = []
        cache_hits = 0
        
        for token in unique_tokens:
            token_lower = token.lower()
            if token_lower in decimals_cache:
                result[token] = decimals_cache[token_lower]
                cache_hits += 1
            else:
                tokens_to_fetch.append(token)
        
        if not tokens_to_fetch:
            self.logger.info(f"‚úÖ –í—Å–µ {len(unique_tokens)} decimals –∏–∑ –∫—ç—à–∞ (100% cache hit)")
            return result
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ decimals –±–∞—Ç—á–∞–º–∏ —á–µ—Ä–µ–∑ ANKR
        BATCH_SIZE = 100
        n_batches = (len(tokens_to_fetch) + BATCH_SIZE - 1) // BATCH_SIZE
        cache_percent = (cache_hits / len(unique_tokens)) * 100 if unique_tokens else 0
        self.logger.info(f"üîÑ fetch_decimals: –∫—ç—à {cache_hits}/{len(unique_tokens)} ({cache_percent:.1f}%), –∑–∞–≥—Ä—É–∂–∞—é {len(tokens_to_fetch)} –Ω–æ–≤—ã—Ö")
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Å–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞
        await self.ensure_session()
        
        for i in range(0, len(tokens_to_fetch), BATCH_SIZE):
            batch = tokens_to_fetch[i:i + BATCH_SIZE]
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞—Ç—á-–∑–∞–ø—Ä–æ—Å –¥–ª—è decimals
            batch_payload = []
            for j, token_address in enumerate(batch):
                batch_payload.append({
                    "jsonrpc": "2.0",
                    "method": "eth_call",
                    "params": [{
                        "to": token_address,
                        "data": "0x313ce567"  # decimals()
                    }, "latest"],
                    "id": j + 1
                })
            
            try:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞—Ç—á —á–µ—Ä–µ–∑ ANKR
                async with self.session.post(self.ankr_url, json=batch_payload, timeout=30) as response:
                    results = await response.json()
                    
                    if isinstance(results, list):
                        for j, token_address in enumerate(batch):
                            if j < len(results) and "result" in results[j]:
                                try:
                                    decimals = int(results[j]["result"], 16)
                                    result[token_address] = decimals
                                    decimals_cache[token_address.lower()] = decimals
                                except:
                                    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 18
                                    result[token_address] = 18
                                    decimals_cache[token_address.lower()] = 18
                            else:
                                result[token_address] = 18
                                decimals_cache[token_address.lower()] = 18
            except Exception as e:
                self.logger.warning(f"Failed to get decimals for batch: {e}")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –≤—Å–µ–≥–æ –±–∞—Ç—á–∞
                for token_address in batch:
                    result[token_address] = 18
                    decimals_cache[token_address.lower()] = 18
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫—ç—à
        try:
            with open(cache_file, 'w') as f:
                json.dump(decimals_cache, f, indent=2)
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à decimals: {e}")
        
        elapsed = time.time() - start_time
        new_fetched = len(tokens_to_fetch)
        self.logger.info(f"‚úÖ Decimals –≥–æ—Ç–æ–≤—ã: {cache_hits} –∏–∑ –∫—ç—à–∞ + {new_fetched} –Ω–æ–≤—ã—Ö = {len(result)} total –∑–∞ {elapsed:.2f}s")
        
        return result
    
    def _parse_reserves(self, result, pairs):
        """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç Ankr"""
        reserves_map = {}
        
        if "result" in result:
            data = result["result"]
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º getReserves() —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            # Returns (uint112 reserve0, uint112 reserve1, uint32 blockTimestampLast)
            reserve0 = int(data[2:66], 16) if len(data) > 66 else 0
            reserve1 = int(data[66:130], 16) if len(data) > 130 else 0
            
            reserves_map[pairs[0]] = {
                'reserve0': reserve0,
                'reserve1': reserve1
            }
        
        return reserves_map
    
    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã"""
        if self.session and not self.session.closed:
            await self.session.close()
            self.session = None
            self.logger.debug("HTTP —Å–µ—Å—Å–∏—è ANKR –∑–∞–∫—Ä—ã—Ç–∞")